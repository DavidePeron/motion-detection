% !TEX root = template.tex

\section{Processing Pipeline}
\label{sec:processing_architecture}
The project can be divided in 3 parts: the dataset creation, the neural network creation and the benchmark prediction.
In order to make an action recognition model it was firstly created a proper dataset. All the signals were divided in several overlapping windows and were thrown into a \gls{cnn} made up with convolutional layers and fully connected layers.
When the neural network was trained and validated, 

\MC{(SISTEMA)
- DRAW A DIAGRAM OF THE PIPELINE
- DESCRIPTION OF THE GENERAL APPROACH}

\section{Signals and Dataset}
\label{sec:model}

\subsection{Measurement setup}
The signals the authors have worked on were provided by DLR official website \cite{DLR}. We took into considerations two of the three published Matlab datasets: \textit{ARS\_DLR\_Data\_Set\_V2.mat} and \textit{ARS\_DLR\_Benchmark\_Data\_Set.mat}. 
Both of them are made up of signals recovered by a \gls{mems} based \gls{imu} (an Xsens MTx-28A53G25) composed by an accelerometer, a gyroscope and a magnetometer. These measurements systems provide informations about the inertial acceleration, the angular velocity and the magnetic field direction.
At the experiment joined fourteen people and the \gls{imu}, that was positioned over the pelvic region of each one (\fig{fig:IMU}), recovered signals during some ordinary motion activities like \textit{standing}, \textit{sitting}, \textit{running}, \textit{jumping}, \textit{lying} and all the transitional phases from an activity to another.

\begin{figure}[htp]
\includegraphics[scale=1.2]{IMU_sensor.pdf}
\caption{Sensor position and the representation of the body frame}
\label{fig:IMU}
\end{figure}

The considered datasets are divided only because they have to be used in different ways, but they are going to be described in the same way according to their identity.

Both datasets are divided in activity sessions, 34 in \textit{ARS\_DLR\_Data\_Set\_V2.mat} and 3 in \textit{ARS\_DLR\_Benchmark\_Data\_Set.mat}, each session is a structure in turn \MR{(a sua volta)} that contains: a matrix of 10 column in which the first column represents the time domain and the other ones represents the \gls{imu} records over the three sensor coordinate, a rotation matrix that has the same dimension of the first one that permits to turn to the global frame the first matrix, a vector that contains the activity labels performed during the session (see \tab{tab:label}) and lastly a vector that indicates when each activity starts and ends.

\begin{table}[htp]
\small
	\centering
		\renewcommand{\arraystretch}{1}% Tighter
	\begin{tabular}{@{}lll@{}}
	\toprule
	Label & Index & Description\\ \midrule
	'RUNNING' & $0$ & running \\
	'WALKING' & $1$ & walking \\
	'JUMPING' & $2$ & jumping  \\
	'STNDING' & $3$ & standing \\ 
	'SITTING' & $4$ & sitting\\
	'XLYINGX' & $5$ & lying \\
	'FALLING' & $6$ & falling \\
	'TRANSUP' & $7$ & getting up i.e.: from sitting to standing \\
	'TRANSDW' & $8$ & going down i.e.: from standing to sitting\\
	'TRNSACC' & $9$ & accelerating\\
	'TRNSDCC' & $10$ & deccelerating\\
	%'TRANSIT' & $11$ & other transition or irrelevant information\\
	\bottomrule
	\end{tabular}
	\caption{Activities took into consideration with the associated labels}
	\label{tab:label}
\end{table}


\subsection{Signal pre-processing}
The first pre-processing applied to the dataset consisted in representing the signals according to the global frame using the rotation matrix \MC{should I say more?}. The dataset considered already contains pre-processed data, sampled with T = 0.01 s. 

In \fig{fig:acc}, \fig{fig:gyr} and \fig{fig:mag} is showed one of the Susanna activity sessions. These figures represent the norm (see \eq{eq:norm}) of accelerometer, gyroscope and magnetometer over the three global coordinates instead of three figures for each measurement system. This is only a convenient choose according to the visual meaningfulness of the norm. 
\MC{From these figures emerges that the mean of angular velocity and the magnetic field swings around zero, on the other hand the acceleration mean shifts near 9.8 m/s according to the gravitational constant value \textit{g}---IT'S WRONG! SEE MAGNETIC FIELD MAGNITUDE}.


\begin{equation}
|s| = \sqrt{s_x^2+s_y^2+s_z^2}
\label{eq:norm}
\end{equation}
%\caption{Norm of s, s can be one of acceleration, angular velocity or mangnetometer}
\MC{problems with caption in the norm equation}


It also emerges in each of these figures how the transitory activities from standing to sitting and vice versa can be observable due to the drastic change of the signals.

\begin{figure}[htp]
\includegraphics[scale=0.55]{acceleration_susanna.pdf}
\caption{Acceleration norm}
\label{fig:acc}
\end{figure}

\begin{figure}[htp]
\includegraphics[scale=0.55]{angular_velocity_susanna.pdf}
\caption{Angular velocity norm}
\label{fig:gyr}
\end{figure}

\begin{figure}[htp]
\includegraphics[scale=0.55]{magnetic_field_susanna.pdf}
\caption{Magnetic field norm}
\label{fig:mag}
\end{figure}


Another sort of pre-processing was made in order to fix the activity indexing of some recordings. It frequently happened to find that, considering two adjacent motion activities, the end of the previous activity and the beginning of the succeeding one were not temporarily neighboring. It happened also to find two activities temporarily overlapping: the end of the previous activity was indexed after the beginning of the second one. 
The authors resolved the problem removing the non indexed data and the data whose label was uncertain so as to not train the \gls{nn} with wrongly labeled data.

Each session is finally represented by a long and straight matrix with nine columns (three for each measurement system) and a number of rows equals to the session duration. Due to the straight sampling time the number of rows stands at around $10^3$-$10^4$ order of magnitude. Even if motion signals are not two dimensional signals, the peculiarity of input shape makes it suitable to be treated as a kind of image. Therefore according to the adopted strategy of \textit{Gadaleta et al.}, the dataset was processed in order to be fit into a \gls{cnn} \cite{Gadaleta-2018}.


Since the \gls{cnn} needs a fixed input the authors decided to divide in patterns each session matrix and associate to them the corresponding label. The pattern length was decided equal to 27, that is the shortest activity length in the whole dataset. 

Then it was taken every activity and it was divided in overlapping windows with stride equals to 3. The obtained final dataset was made by several windows associated to a specific activity. No transitional pattern from an activity to another were taken. 


The last procedure attuated was a shuffle of the dataset.


\section{Learning Framework}
\label{sec:learning_framework}

\subsection{\gls{cnn} architecture}

\begin{figure}[htp]
\includegraphics[scale=1.75]{CNN_arch.pdf}
\caption{\gls{cnn} architecture}
\label{fig:CNN}
\end{figure}

\MC{HERE I'D PUT SOME PROCESSOR CHARACTERISICS}


The \gls{cnn} architecture is schematically presented in \fig{fig:CNN} and in this section is going to be explained in details using the showed labeling of the layers. 
Because of the fixed input shape of the \gls{cnn}, the dataset is composed by 322502 patterns with shape (27,9) and it was divided in two subsets\MC{according to a common Machine Learning working iter(?)}: the \textit{training set} that is constituted by the 80\% of the whole patterns (258002), the remaining part forms the \textit{validation set}.

Due to the restrictive number of columns it was decided to learn the feature for each column separately in the convolutional layers, it was used infact 1D-\glspl{cnn}, and then classify the whole pattern in the succeeding fully connected layers. 

The choosed \gls{cnn} architecture presents first of all Zero Padding at the first and last 2 rows of each pattern so the shape of the dataset pattern began (31,9). 

The first 1D convolutional layer Conv1 returns 64 filters of shape (27,9) and Conv2 returns the same number fo filters with a shape of (23,9). The kernel used in these two first layers has (5,1) shape and a stride of (1,1). 
Conv3 and Conv4 present a kernel of size (3,1) and a stride of (1,1) instead, the outputs are both 32 filters of respecively (21,9) and (19,9) shape.
\tab{tab:filtersize} shows how the filters size of each convolutional layer can be mathematically calculated. After each convolutional layer was added a Batch Normalization and a "ReLu" Activation Function.

After this feature learning block follows a classification part made of three fully connected layers:to allow this passage a flattening of Conv4 output filters in necessary (see Flatten layer in \fig{fig:CNN}). Then follows three fully connected layers of size respecively 256, 128 and 11. The last one is the output and presents a size equal to the number of the activity labels considered.

\MC{Lastly were added also Dropout to make the \gls{nn} not to learn too specificatamente /to memorize the training dataset}

\MC{model.optimizer missing}


\MC{The \gls{nn} was not trained with transitional patterns.}



\begin{table}[htp]
\small
	\centering
		\renewcommand{\arraystretch}{1}% Tighter
	\begin{tabular}{@{}lllll@{}}
	\toprule
	LAYER & N & K & S & OUTPUT\\
	\midrule
	CONV1 & $31$ & $5$ & $1$ & $(31-5)/1+1 = 27$\\
	CONV2 & $27$ & $5$ & $1$ & $(27-5)/1+1 = 23$\\
	CONV3 & $27$ & $3$ & $1$ & $(23-3)/1+1 = 21$\\
	CONV4 & $21$ & $3$ & $1$ & $(21-3)/1+1 = 19$\\ 
	\bottomrule
	\end{tabular}
	\caption{Filters dimension along the pattern columns. N is the number of rows of the input pattern. K is the dimension of the kernel. S is the stride dimension.}
	\label{tab:filtersize}
\end{table}




\subsection{\gls{cnn} results}

The \gls{nn} was trained for 10 epochs with a batch size of 128\MC{verifica!}





